{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37c0db08-e256-44fa-abb3-e4b232bc5312",
   "metadata": {},
   "source": [
    "# Get Uber Ride Data\n",
    "\n",
    "As a full-time Uber driver, I'm interested in performing analysis on my past rides so I can make informed choices about driving in the future and how to optimize for higher earnings. However, when I log in to the [Uber Drivers](https://drivers.uber.com/earnings/activities) page, I can only view my past rides a week at a time, and that weekly view is frustratingly paginated and lacks relevant details. Being a programmer, I naturally thought of downloading the data through an API. As of August 24, 2024 access to the [Uber Drivers API](https://developer.uber.com/docs/drivers/introduction) is \"limited\" and there's a vague message on their info page about applying for access. So that's not a solution for my personal data needs. \n",
    "\n",
    "**Caveat**: This is likely against the Uber Drivers TOS and I'm engaging with this at my own risk of potentially haveing my account limited/banned, but I really want to get this data and I'm requesting in a reasonable manner. **Proceed at your own risk.** \n",
    "\n",
    "## Reverse Engineering the Uber Drivers page\n",
    "\n",
    "By going into the Google Chrome Developer Console Network tab when loading the Uber Drivers page, I can see that the weekly paginated rides data is initially retrieved through an HTTP POST request to `https://drivers.uber.com/earnings/api/getWebActivityFeed?localeCode=en` with the request payload:\n",
    "\n",
    "```\n",
    "{\"startDateIso\":\"2024-05-13\",\"endDateIso\":\"2024-05-20\",\"paginationOption\":{}}\n",
    "```\n",
    "\n",
    "This retrieves a JSON object including my rides data that's far richer than what's actually displayed on the page. Jackpot! \n",
    "\n",
    "If there are more pages of data, then the JSON object `data` has `data['data']['pagination']['hasMoreData']` set to `True`. There is then a pagination cursor value available in `data['data']['pagination']['nextCursor']`, and the next page of data can be requested with a similar HTTP POST request to `https://drivers.uber.com/earnings/api/getWebActivityFeed?localeCode=en` with the request payload:\n",
    "\n",
    "```\n",
    "{\"startDateIso\":\"2024-05-13\",\"endDateIso\":\"2024-05-20\",\"paginationOption\":{\"cursor\": data['data']['pagination']['nextCursor']}}\n",
    "```\n",
    "\n",
    "Repeating this request until `data['data']['pagination']['hasMoreData']` is `False` will retrieve all data for that time period. \n",
    "\n",
    "Performing this entire series of requests for all weekly date ranges from the date I started driving Uber (2023-01-09) to now will get me all of my ride data. \n",
    "\n",
    "Importantly, this is all occurring inside an authenticated HTTPS session. In my initial discovery and testing, I used Postman to perform the requests. Through the Network tab in the Google Chrome Developer Console, I right-clicked the POST request, chose `Copy > Copy as cURL`, and then imported that into Postman using `File > Import...`. \n",
    "\n",
    "After confirming it worked, I migrated to Python to request everything programmatically. To generate starter code for Python requests, in Postman on this particular request I chose the `Code` option in the pane on the right side of the window, then chose \"Python - Requests\" from the drop-down menu. This includes the full authentication tokens in plaintext on the `cookies` key of the headers dictionary. \n",
    "\n",
    "With all of the data downloaded, I extract the rides data specifically and save this to a local JSON file so I don't have to re-request the data. I then perform some data cleaning, parsing, and enrichment to ultimately produce CSV files that I can easily analyze with other programs and import into a spreadsheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02ccdf3-6a47-4341-9f7c-52101465cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d37fc9-757c-43ac-bd35-85001a9c6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UberDriver:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "          'accept': '*/*',\n",
    "          'accept-language': 'en-US,en;q=0.9',\n",
    "          'content-type': 'application/json',\n",
    "          'cookie': 'marketing_vistor_id=e6179b1a-9343-4ccf-94f3-49c0a0872691; udi-id=96R0deYd5NKtgpGIU0qFlFAcBzBQdTIRqsIlYJbvKhZuroYcx6SkceuzEon93iJ1/4V6+aiHnY4FEB1asER6hueGDGiVa+rD521twej17+B6ZIhp+seAhGU26SYRIVM90DgeCyb6L5jVWA7X2q7g4WwpAdBUzfnV4+M2TqnoBJ/bUQiS5a9rOHzFhVo6lCk84g8Aa3PHc6xcKn/3Hl64DQ==fvhyJitF/W+NoxdxMgTOVQ==Kt6etXM12v3JFy3hyJfCG/nDTSP3v9qMot79dk8GMWw=; _ga=GA1.2.1479445038.1725558410; _ua={\"session_id\":\"35d416d9-038a-4ef5-8c4b-5a3cb64ba693\",\"session_time_ms\":1726067606130}; x-uber-analytics-session-id=2d9df78f-8237-4399-9dad-ea95b85d3bcf; udi-fingerprint=IsfVqvFQ6U7zXjFSex9f78kOt9zUKBxnLMvggArLxEMtiS7QjdX8UH4ALuWvgQqbkA3xO0RLlZxwvhhS7ys/gw==I85WUL/fsmgUX2zxrmk6W7+y3np06/p4fHTM3m2d55Q=; isWebLogin=true; sid=QA.CAESELaVBpfVeUpBmXnJnLbcKf0Y3ImLuQYiATEqJDYwOTJiYWFkLTAxYjMtNDRiYi1iZTE2LTAxZDZlMWIzYWM5YzJAFL-KaHDZrJxSY84kGACPtifIhJITxWJMt9EFAkz1y0Uc-Ob9oDNei1ZWE14aT_t2gdlVYeu8gSlVvyA0rVmvUDoBMUIIdWJlci5jb20.NQ0u6aQmFYoFvoj2ZhI6Fg1xup7yaAx4xlPYfcljnss; csid=1.1730331868279.JDd4PJtx+7GeNJ6ML2hoPisPYOjY1Q6OD15otAUshok=; jwt-session=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE3Mjc3Mzk4NzQsImV4cCI6MTcyNzgyNjI3NH0.lYcWnzcy07MFT13LWx9JmkOJCYIePPjh4unR8_LRz54; mp_adec770be288b16d9008c964acfba5c2_mixpanel=%7B%22distinct_id%22%3A%20%226092baad-01b3-44bb-be16-01d6e1b3ac9c%22%2C%22%24device_id%22%3A%20%2219182de2167581-04c7044d865e5-18525637-13c680-19182de21681438%22%2C%22%24initial_referrer%22%3A%20%22https%3A%2F%2Fauth.uber.com%2F%22%2C%22%24initial_referring_domain%22%3A%20%22auth.uber.com%22%2C%22%24user_id%22%3A%20%226092baad-01b3-44bb-be16-01d6e1b3ac9c%22%2C%22%24search_engine%22%3A%20%22google%22%7D',\n",
    "          'origin': 'https://drivers.uber.com',\n",
    "          'priority': 'u=1, i',\n",
    "          'referer': 'https://drivers.uber.com/earnings/activities',\n",
    "          'sec-ch-ua': '\"Google Chrome\";v=\"129\", \"Not=A?Brand\";v=\"8\", \"Chromium\";v=\"129\"',\n",
    "          'sec-ch-ua-mobile': '?0',\n",
    "          'sec-ch-ua-platform': '\"macOS\"',\n",
    "          'sec-fetch-dest': 'empty',\n",
    "          'sec-fetch-mode': 'cors',\n",
    "          'sec-fetch-site': 'same-origin',\n",
    "          'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',\n",
    "          'x-csrf-token': 'x',\n",
    "          'x-uber-earnings-seed': '70946254c2d18c0633a83cf845ab98f2'\n",
    "        }\n",
    "\n",
    "    \n",
    "    def get_rides(self, start_date_iso, end_date_iso):        \n",
    "        url = \"https://drivers.uber.com/earnings/api/getWebActivityFeed?localeCode=en\"\n",
    "    \n",
    "        payload = json.dumps({\n",
    "          \"startDateIso\": start_date_iso,\n",
    "          \"endDateIso\": end_date_iso,\n",
    "          \"paginationOption\": {}\n",
    "        })\n",
    "        \n",
    "        response = requests.request(\"POST\", url, headers=self.headers, data=payload)\n",
    "        data = response.json()\n",
    "\n",
    "        rides = data['data']['activities']\n",
    "        while data['data']['pagination']['hasMoreData']:\n",
    "            payload = json.dumps({\n",
    "              \"startDateIso\": start_date_iso,\n",
    "              \"endDateIso\": end_date_iso,\n",
    "              \"paginationOption\": {\"cursor\": data['data']['pagination']['nextCursor']}\n",
    "            })\n",
    "            response = requests.request(\"POST\", url, headers=self.headers, data=payload)\n",
    "            data = response.json()\n",
    "            if data['data']['activities']:\n",
    "                rides = rides + data['data']['activities']\n",
    "        return rides or []\n",
    "\n",
    "    def get_ride_detail(self, ride_uuid):\n",
    "        # This is only helpful to get additional fare breakdown from Uber, if we wanted to analyze how much\n",
    "        # Uber is taking from each fare.\n",
    "        url = f\"https://drivers.uber.com/earnings/trips/{ride_uuid}\"\n",
    "        response = requests.request(\"GET\", url, headers=self.headers)\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce03ce-e280-4f38-ad1a-9db36be7ccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting rides for 2023-01-09 - 2023-01-16...\n",
      "Retrieved 42 rides.\n",
      "Getting rides for 2023-01-16 - 2023-01-23...\n",
      "Retrieved 9 rides.\n",
      "Getting rides for 2023-01-23 - 2023-01-30...\n",
      "Retrieved 13 rides.\n",
      "Getting rides for 2023-01-30 - 2023-02-06...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-02-06 - 2023-02-13...\n",
      "Retrieved 26 rides.\n",
      "Getting rides for 2023-02-13 - 2023-02-20...\n",
      "Retrieved 26 rides.\n",
      "Getting rides for 2023-02-20 - 2023-02-27...\n",
      "Retrieved 7 rides.\n",
      "Getting rides for 2023-02-27 - 2023-03-06...\n",
      "Retrieved 29 rides.\n",
      "Getting rides for 2023-03-06 - 2023-03-13...\n",
      "Retrieved 9 rides.\n",
      "Getting rides for 2023-03-13 - 2023-03-20...\n",
      "Retrieved 51 rides.\n",
      "Getting rides for 2023-03-20 - 2023-03-27...\n",
      "Retrieved 59 rides.\n",
      "Getting rides for 2023-03-27 - 2023-04-03...\n",
      "Retrieved 26 rides.\n",
      "Getting rides for 2023-04-03 - 2023-04-10...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-04-10 - 2023-04-17...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-04-17 - 2023-04-24...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-04-24 - 2023-05-01...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-05-01 - 2023-05-08...\n",
      "Retrieved 6 rides.\n",
      "Getting rides for 2023-05-08 - 2023-05-15...\n",
      "Retrieved 11 rides.\n",
      "Getting rides for 2023-05-15 - 2023-05-22...\n",
      "Retrieved 3 rides.\n",
      "Getting rides for 2023-05-22 - 2023-05-29...\n",
      "Retrieved 19 rides.\n",
      "Getting rides for 2023-05-29 - 2023-06-05...\n",
      "Retrieved 14 rides.\n",
      "Getting rides for 2023-06-05 - 2023-06-12...\n",
      "Retrieved 12 rides.\n",
      "Getting rides for 2023-06-12 - 2023-06-19...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-06-19 - 2023-06-26...\n",
      "Retrieved 18 rides.\n",
      "Getting rides for 2023-06-26 - 2023-07-03...\n",
      "Retrieved 3 rides.\n",
      "Getting rides for 2023-07-03 - 2023-07-10...\n",
      "Retrieved 12 rides.\n",
      "Getting rides for 2023-07-10 - 2023-07-17...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-07-17 - 2023-07-24...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-07-24 - 2023-07-31...\n",
      "Retrieved 18 rides.\n",
      "Getting rides for 2023-07-31 - 2023-08-07...\n",
      "Retrieved 41 rides.\n",
      "Getting rides for 2023-08-07 - 2023-08-14...\n",
      "Retrieved 34 rides.\n",
      "Getting rides for 2023-08-14 - 2023-08-21...\n",
      "Retrieved 45 rides.\n",
      "Getting rides for 2023-08-21 - 2023-08-28...\n",
      "Retrieved 58 rides.\n",
      "Getting rides for 2023-08-28 - 2023-09-04...\n",
      "Retrieved 39 rides.\n",
      "Getting rides for 2023-09-04 - 2023-09-11...\n",
      "Retrieved 30 rides.\n",
      "Getting rides for 2023-09-11 - 2023-09-18...\n",
      "Retrieved 37 rides.\n",
      "Getting rides for 2023-09-18 - 2023-09-25...\n",
      "Retrieved 33 rides.\n",
      "Getting rides for 2023-09-25 - 2023-10-02...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-10-02 - 2023-10-09...\n",
      "Retrieved 65 rides.\n",
      "Getting rides for 2023-10-09 - 2023-10-16...\n",
      "Retrieved 63 rides.\n",
      "Getting rides for 2023-10-16 - 2023-10-23...\n",
      "Retrieved 36 rides.\n",
      "Getting rides for 2023-10-23 - 2023-10-30...\n",
      "Retrieved 62 rides.\n",
      "Getting rides for 2023-10-30 - 2023-11-06...\n",
      "Retrieved 54 rides.\n",
      "Getting rides for 2023-11-06 - 2023-11-13...\n",
      "Retrieved 81 rides.\n",
      "Getting rides for 2023-11-13 - 2023-11-20...\n",
      "Retrieved 49 rides.\n",
      "Getting rides for 2023-11-20 - 2023-11-27...\n",
      "Retrieved 36 rides.\n",
      "Getting rides for 2023-11-27 - 2023-12-04...\n",
      "Retrieved 102 rides.\n",
      "Getting rides for 2023-12-04 - 2023-12-11...\n",
      "Retrieved 91 rides.\n",
      "Getting rides for 2023-12-11 - 2023-12-18...\n",
      "Retrieved 101 rides.\n",
      "Getting rides for 2023-12-18 - 2023-12-25...\n",
      "Retrieved 103 rides.\n",
      "Getting rides for 2023-12-25 - 2024-01-01...\n",
      "Retrieved 100 rides.\n",
      "Getting rides for 2024-01-01 - 2024-01-08...\n",
      "Retrieved 154 rides.\n",
      "Getting rides for 2024-01-08 - 2024-01-15...\n",
      "Retrieved 73 rides.\n",
      "Getting rides for 2024-01-15 - 2024-01-22...\n",
      "Retrieved 48 rides.\n",
      "Getting rides for 2024-01-22 - 2024-01-29...\n",
      "Retrieved 77 rides.\n",
      "Getting rides for 2024-01-29 - 2024-02-05...\n",
      "Retrieved 96 rides.\n",
      "Getting rides for 2024-02-05 - 2024-02-12...\n",
      "Retrieved 60 rides.\n",
      "Getting rides for 2024-02-12 - 2024-02-19...\n",
      "Retrieved 82 rides.\n",
      "Getting rides for 2024-02-19 - 2024-02-26...\n",
      "Retrieved 58 rides.\n",
      "Getting rides for 2024-02-26 - 2024-03-04...\n",
      "Retrieved 61 rides.\n",
      "Getting rides for 2024-03-04 - 2024-03-11...\n",
      "Retrieved 86 rides.\n",
      "Getting rides for 2024-03-11 - 2024-03-18...\n",
      "Retrieved 131 rides.\n",
      "Getting rides for 2024-03-18 - 2024-03-25...\n",
      "Retrieved 84 rides.\n",
      "Getting rides for 2024-03-25 - 2024-04-01...\n",
      "Retrieved 124 rides.\n",
      "Getting rides for 2024-04-01 - 2024-04-08...\n",
      "Retrieved 98 rides.\n",
      "Getting rides for 2024-04-08 - 2024-04-15...\n",
      "Retrieved 97 rides.\n",
      "Getting rides for 2024-04-15 - 2024-04-22...\n",
      "Retrieved 50 rides.\n",
      "Getting rides for 2024-04-22 - 2024-04-29...\n",
      "Retrieved 63 rides.\n",
      "Getting rides for 2024-04-29 - 2024-05-06...\n",
      "Retrieved 71 rides.\n",
      "Getting rides for 2024-05-06 - 2024-05-13...\n",
      "Retrieved 88 rides.\n",
      "Getting rides for 2024-05-13 - 2024-05-20...\n",
      "Retrieved 77 rides.\n",
      "Getting rides for 2024-05-20 - 2024-05-27...\n",
      "Retrieved 71 rides.\n",
      "Getting rides for 2024-05-27 - 2024-06-03...\n",
      "Retrieved 74 rides.\n",
      "Getting rides for 2024-06-03 - 2024-06-10...\n",
      "Retrieved 58 rides.\n",
      "Getting rides for 2024-06-10 - 2024-06-17...\n",
      "Retrieved 42 rides.\n",
      "Getting rides for 2024-06-17 - 2024-06-24...\n",
      "Retrieved 76 rides.\n",
      "Getting rides for 2024-06-24 - 2024-07-01...\n",
      "Retrieved 77 rides.\n",
      "Getting rides for 2024-07-01 - 2024-07-08...\n",
      "Retrieved 45 rides.\n",
      "Getting rides for 2024-07-08 - 2024-07-15...\n",
      "Retrieved 35 rides.\n",
      "Getting rides for 2024-07-15 - 2024-07-22...\n",
      "Retrieved 14 rides.\n",
      "Getting rides for 2024-07-22 - 2024-07-29...\n",
      "Retrieved 28 rides.\n",
      "Getting rides for 2024-07-29 - 2024-08-05...\n",
      "Retrieved 31 rides.\n",
      "Getting rides for 2024-08-05 - 2024-08-12...\n",
      "Retrieved 106 rides.\n",
      "Getting rides for 2024-08-12 - 2024-08-19...\n",
      "Retrieved 123 rides.\n",
      "Getting rides for 2024-08-19 - 2024-08-26...\n",
      "Retrieved 144 rides.\n",
      "Getting rides for 2024-08-26 - 2024-09-02...\n",
      "Retrieved 96 rides.\n",
      "Getting rides for 2024-09-02 - 2024-09-09...\n",
      "Retrieved 94 rides.\n",
      "Getting rides for 2024-09-09 - 2024-09-16...\n",
      "Retrieved 99 rides.\n",
      "Getting rides for 2024-09-16 - 2024-09-23...\n",
      "Retrieved 90 rides.\n",
      "Getting rides for 2024-09-23 - 2024-09-30...\n",
      "Retrieved 31 rides.\n",
      "Getting rides for 2024-09-30 - 2024-10-07...\n",
      "Retrieved 0 rides.\n",
      "Retrieved 4685 rides total.\n"
     ]
    }
   ],
   "source": [
    "uber = UberDriver()\n",
    "\n",
    "# This is the date I started working as an Uber driver; modify for your start date\n",
    "start_date = datetime.strptime(\"2023-01-09\", \"%Y-%m-%d\")\n",
    "end_date = datetime.today()\n",
    "current_date = start_date\n",
    "\n",
    "rides = []\n",
    "while current_date <= end_date:\n",
    "    next_date = current_date + timedelta(days = 7)\n",
    "    start_date_iso = current_date.strftime('%Y-%m-%d')\n",
    "    end_date_iso = next_date.strftime('%Y-%m-%d')\n",
    "    print(f\"Getting rides for {start_date_iso} - {end_date_iso}...\")\n",
    "    new_rides = uber.get_rides(start_date_iso, end_date_iso)\n",
    "    print(f\"Retrieved {len(new_rides)} rides.\")\n",
    "    rides += new_rides\n",
    "    current_date = next_date\n",
    "\n",
    "# Let's dump all of these rides to a JSON file so we can reference this data outside of the script if need be, \n",
    "# or simply not have to retrieve from Uber again.\n",
    "with open(f\"../data/rides_raw.json\", \"w\") as file:\n",
    "    json.dump(rides, file)\n",
    "\n",
    "print(f\"Retrieved {len(rides)} rides total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3a9f937-fd54-4205-841b-195e1b2fb0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   uuid  recognizedAt activityTitle  \\\n",
      "0  d3096d6c-02bd-4f8e-855b-117588b27910    1673809557       Comfort   \n",
      "1  89a3e777-2000-44af-8509-765b157dfe9e    1673808331         UberX   \n",
      "2  78616fc5-6214-4f31-89a0-4229e35f0c5c    1673807621         UberX   \n",
      "3  b6457299-8e46-44ec-b151-398649205336    1673806661         UberX   \n",
      "4  ae817bfc-76a2-4a47-8622-d85cc9b5dd8e    1673802749         UberX   \n",
      "\n",
      "  formattedTotal                                            routing  \\\n",
      "0         $10.72  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "1          $4.13  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "2          $7.56  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "3         $11.19  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "4         $10.48  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "\n",
      "                                    breakdownDetails  \\\n",
      "0  {'formattedTip': '$1.00', 'formattedSurge': None}   \n",
      "1                                               None   \n",
      "2  {'formattedTip': '$3.00', 'formattedSurge': None}   \n",
      "3  {'formattedTip': '$3.00', 'formattedSurge': '$...   \n",
      "4  {'formattedTip': '$3.00', 'formattedSurge': None}   \n",
      "\n",
      "                                        tripMetaData  type     status  \n",
      "0  {'formattedDuration': '15 min 56 sec', 'format...  TRIP  COMPLETED  \n",
      "1  {'formattedDuration': '13 min 55 sec', 'format...  TRIP  COMPLETED  \n",
      "2  {'formattedDuration': '10 min 42 sec', 'format...  TRIP  COMPLETED  \n",
      "3  {'formattedDuration': '11 min 53 sec', 'format...  TRIP  COMPLETED  \n",
      "4  {'formattedDuration': '21 min 57 sec', 'format...  TRIP  COMPLETED  \n",
      "\n",
      "Unique values for ride type:\n",
      "\n",
      "['TRIP' 'MISC' 'CT' 'QUEST']\n",
      "\n",
      "Unique values for ride activityTitle:\n",
      "\n",
      "['Comfort' 'UberX' 'Connect Express' 'UberXL' 'Time Adjustment'\n",
      " 'UberX Share' 'Delivery' 'Connect Saver' 'Adjustment' 'Quest'\n",
      " 'Miscellaneous Adjustment' 'Lost Item Return' 'UberX Priority' 'Uber Pet'\n",
      " 'Incentive' 'Package Express' 'Business Comfort' 'Payment for past trip'\n",
      " '{0} Trip Quest' 'Share']\n"
     ]
    }
   ],
   "source": [
    "# Let's re-load rides using what's in the JSON file to confirm that it's what we need.\n",
    "# We can also re-run from this point onward without having to hit the Uber site again.\n",
    "rides_df = pd.read_json('../data/rides_raw.json')\n",
    "\n",
    "# Let's see what the ride data looks like\n",
    "print(rides_df.head())\n",
    "print(\"\\nUnique values for ride type:\\n\")\n",
    "print(rides_df['type'].unique())\n",
    "print(\"\\nUnique values for ride activityTitle:\\n\")\n",
    "print(rides_df['activityTitle'].unique())\n",
    "\n",
    "# There's some deeply nested JSON data in these fields, so a dataframe isn't the right form yet. I'll convert to \n",
    "# a list of dicts and clean it up there. \n",
    "rides = rides_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc753e16-1bdb-46d1-a4b2-6ae7cde57668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time_to_seconds(time_str):\n",
    "    matches = re.findall(r'(\\d+)\\s*(hr|min|sec)', time_str)\n",
    "    unit_to_seconds = {'hr': 3600, 'min': 60, 'sec': 1}\n",
    "    return sum(int(value) * unit_to_seconds[unit] for value, unit in matches)\n",
    "\n",
    "def parse_miles(miles_str):\n",
    "    match = re.search(r'(\\d+\\.?\\d*)\\s*mi', miles_str)\n",
    "    return float(match.group(1))\n",
    "\n",
    "def parse_currency_to_float(currency_str):\n",
    "    clean_str = currency_str.replace('$', '').strip()\n",
    "    return float(clean_str)\n",
    "\n",
    "def parse_season(date):\n",
    "    \"\"\"Return the season for a given datetime object.\"\"\"\n",
    "    seasons = {\n",
    "        'Spring': (3, 21, 6, 20),\n",
    "        'Summer': (6, 21, 9, 20),\n",
    "        'Fall': (9, 21, 12, 20),\n",
    "        'Winter': (12, 21, 3, 20)\n",
    "    }\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    for season, (start_month, start_day, end_month, end_day) in seasons.items():\n",
    "        if start_month <= end_month:\n",
    "            if start_month <= month <= end_month:\n",
    "                if (month == start_month and day >= start_day) or (month == end_month and day <= end_day) or (start_month < month < end_month):\n",
    "                    return season\n",
    "        else:\n",
    "            if month > start_month or month < end_month or (month == start_month and day >= start_day) or (month == end_month and day <= end_day):\n",
    "                return season\n",
    "\n",
    "def extract_zipcode(address):\n",
    "    zip_code_pattern = re.compile(r'\\b\\d{5}\\b')\n",
    "    match = zip_code_pattern.search(address)\n",
    "    if match:\n",
    "        return match.group()\n",
    "\n",
    "# Filter out any rides that don't have breakdownDetails or tripMetaData, which are present for completed passenger rides\n",
    "rides = [ride for ride in rides if ride.get('breakdownDetails') and ride.get('tripMetaData')]\n",
    "\n",
    "cleaned_rides = []\n",
    "for ride in rides:\n",
    "    # what\n",
    "    ride_type = ride['activityTitle']\n",
    "    status = ride['status']\n",
    "    note = ride['type']\n",
    "    # $$\n",
    "    tip = parse_currency_to_float(ride['breakdownDetails']['formattedTip'] or '$0.00')\n",
    "    surge = parse_currency_to_float(ride['breakdownDetails']['formattedSurge'] or '$0.00')\n",
    "    earnings = parse_currency_to_float(ride['formattedTotal'])\n",
    "    ## where\n",
    "    distance = parse_miles(ride['tripMetaData']['formattedDistance'])\n",
    "    pickup_zip = extract_zipcode(ride['tripMetaData']['pickupAddress'])\n",
    "    dropoff_zip = extract_zipcode(ride['tripMetaData']['dropOffAddress'])\n",
    "    ## when\n",
    "    ride_start = datetime.fromtimestamp(ride['recognizedAt'])\n",
    "    duration = parse_time_to_seconds(ride['tripMetaData']['formattedDuration'])\n",
    "    ride_end = ride_start + timedelta(seconds=duration)\n",
    "    if ride_type in ['Comfort', 'UberX', 'UberXL', 'UberX Share', 'UberX Priority', 'Uber Pet', 'Business Comfort'] \\\n",
    "            and status == 'COMPLETED' \\\n",
    "            and note == 'TRIP' \\\n",
    "            and pickup_zip \\\n",
    "            and dropoff_zip:\n",
    "        cleaned_rides.append({\n",
    "            'type': ride_type,\n",
    "            'tip': tip,\n",
    "            'surge': surge,\n",
    "            'earnings': earnings,\n",
    "            'distance': distance,\n",
    "            'pickup_zip': pickup_zip,\n",
    "            'dropoff_zip': dropoff_zip,\n",
    "            'ride_start': ride_start,\n",
    "            'duration': duration,\n",
    "            'ride_end': ride_end\n",
    "        })\n",
    "\n",
    "rides_df = pd.DataFrame(cleaned_rides)\n",
    "rides_df.to_csv('../data/rides.csv', include_index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
